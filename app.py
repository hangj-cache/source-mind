import os
os.environ["USE_SHM"] = "0"
import io
import tempfile
import numpy as np
import scipy.io as sio
from typing import Tuple, Dict
from flask import Flask, request, jsonify, send_file, after_this_request
# å¿…é¡»å¯¼å…¥ CORSï¼Œå› ä¸ºå‰ç«¯ index.html æ˜¯æœ¬åœ°æ–‡ä»¶ï¼Œä¸æœåŠ¡å™¨ç«¯å£ä¸åŒï¼Œä¼šäº§ç”Ÿè·¨åŸŸé—®é¢˜
import flask_cors
from flask_cors import CORS
import atexit
import shutil # å¯¼å…¥ shutil ç”¨äºæ›´å¼ºå¤§çš„ç›®å½•åˆ é™¤
from os.path import join
import torch

# ä»å·²æä¾›çš„ç®—æ³•æ–‡ä»¶ä¸­å¯¼å…¥æ±‚è§£å™¨
# å‡è®¾æ–‡ä»¶ç»“æ„ä¸º: app.py å’Œ source_mind/ æ–‡ä»¶å¤¹åœ¨åŒä¸€ç›®å½•ä¸‹
try:
    # å¯¼å…¥ MNE/LORETA æ±‚è§£å™¨ã€‚è¯·ç¡®ä¿ source_mind/algorithms/mne_algorithm.py å­˜åœ¨
    from source_mind.algorithms.mne_algorithm import MNE_solver
    # å¯¼å…¥ SBL æ±‚è§£å™¨ã€‚è¯·ç¡®ä¿ source_mind/algorithms/sbl_algorithm.py å­˜åœ¨
    from source_mind.algorithms.sbl_algorithm import SBL_solver
    from source_mind.algorithms.ADMM_Network import ESINetADMMLayer

except ImportError as e:
    print(f"ğŸš¨ å¯¼å…¥ç®—æ³•æ–‡ä»¶å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶ç»“æ„: {e}")
    print("å¦‚æœæ‚¨å°šæœªåˆ›å»ºç®—æ³•æ–‡ä»¶ï¼Œè¯·åœ¨ source_mind/algorithms/ ä¸‹åˆ›å»ºå®ƒä»¬ï¼Œå¹¶å®šä¹‰ MNE_solver å’Œ SBL_solver å‡½æ•°ã€‚")


# =================================================================
# === Flask åº”ç”¨è®¾ç½® ===
# =================================================================

app = Flask(__name__)
# å…è®¸å‰ç«¯è·¨åŸŸè°ƒç”¨ APIï¼Œé»˜è®¤ç«¯å£ 5000
CORS(app)

# ä¸´æ—¶ç›®å½•ç”¨äºä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
TEMP_DIR = tempfile.mkdtemp()
# atexit.register(lambda: os.path.isdir(TEMP_DIR) and os.removedirs(TEMP_DIR))
atexit.register(lambda: os.path.isdir(TEMP_DIR) and shutil.rmtree(TEMP_DIR))

# RESULT_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), "result")
RESULT_DIR = os.path.join("source_mind/", "result")
os.makedirs(RESULT_DIR, exist_ok=True)


@app.route('/run_localization', methods=['POST'])
def run_localization():
    """
    API æ¥å£ï¼šæ¥æ”¶æ–‡ä»¶å’Œç®—æ³•é€‰æ‹©ï¼Œè¿è¡Œæºå®šä½ç®—æ³•ï¼Œå¹¶è¿”å› .mat æ–‡ä»¶ã€‚
    """
    # æ–‡ä»¶è·¯å¾„å­—å…¸ï¼Œç”¨äºå­˜å‚¨ä¸Šä¼ æ–‡ä»¶çš„ä¸´æ—¶è·¯å¾„
    temp_file_paths = {}
    try:
        # 1. è·å–ç®—æ³•åç§°å’Œæ–‡ä»¶
        algorithm = request.form.get('algorithm')

        file_model = request.files.get('model_file')
        file_b_storage = request.files.get('data_file')
        file_cortex = request.files.get('cortex_file')
        file_l = request.files.get('l_file')

        if not algorithm or not file_model or not file_b_storage or not file_cortex or not file_l:
            return jsonify({"error": "ç¼ºå°‘å¿…éœ€çš„å‚æ•° (ç®—æ³•åç§°æˆ– Gain/B_storage/cortex/l æ–‡ä»¶)"}), 400

        # å®šä¹‰ä¸´æ—¶è·¯å¾„
        temp_file_paths['model'] = os.path.join(TEMP_DIR, file_model.filename or 'model.mat')
        temp_file_paths['data'] = os.path.join(TEMP_DIR, file_b_storage.filename or 'data.mat')
        temp_file_paths['cortex'] = os.path.join(TEMP_DIR, file_cortex.filename or 'cortex.mat')
        temp_file_paths['l'] = os.path.join(TEMP_DIR, file_l.filename or 'l.mat')

        # ä¿å­˜æ–‡ä»¶
        file_model.save(temp_file_paths['model'])
        file_b_storage.save(temp_file_paths['data'])
        file_cortex.save(temp_file_paths['cortex'])
        file_l.save(temp_file_paths['l'])

        print(f"âœ” æ‰€æœ‰æ–‡ä»¶å·²ä¿å­˜åˆ°ä¸´æ—¶è·¯å¾„: {TEMP_DIR}")



        channelselect = list(range(0, 32)) + list(range(33, 42)) + list(range(43, 64))
        # -------- 1ï¸âƒ£ Gain ä» model_file è¯»å– --------
        model_data = sio.loadmat(temp_file_paths['model'])
        if "model" not in model_data:
            return jsonify({"error": "model_file ç¼ºå°‘å˜é‡ 'model'"}), 400
        model_struct = model_data.get('model')
        if model_struct is not None and model_struct.shape == (1, 1) and 'Gain' in model_struct[0][0].dtype.fields:
            Gain_data = model_struct[0][0]['Gain']
        else:
            # å¦‚æœä¸æ˜¯ç»“æ„ä½“ï¼Œåˆ™å°è¯•ç›´æ¥ä»é¡¶å±‚å˜é‡ 'Gain' æå–
            Gain_data = model_data.get('Gain')

        selected_gain = Gain_data[channelselect, :]
        print(f"âœ” Gain åŠ è½½æˆåŠŸ: {selected_gain.shape}")

        # -------- 2ï¸âƒ£ B_dataStorage + TBFs_dataStorage ä» data_file è¯»å– --------
        data_dict = sio.loadmat(temp_file_paths['data'])

        # if "B_dataStorage" not in data_dict or "TBFs_dataStorage" not in data_dict:
        #     return jsonify({"error": "data_file ç¼ºå°‘ B_dataStorage æˆ– TBFs_dataStorage"}), 400

        if "B" not in data_dict or "TBFs" not in data_dict:
            return jsonify({"error": "data_file ç¼ºå°‘ B æˆ– TBFs"}), 400

        B_storage = data_dict["B"]
        TBFs_storage = data_dict["TBFs"]
        print(f"âœ” æ•°æ®åŠ è½½æˆåŠŸ: B={B_storage.shape} TBFs={TBFs_storage.shape}")

        # æ‰¹é‡çŸ©é˜µä¹˜æ³• â†’ å¾—åˆ° 50x62x300
        # B_storage = np.matmul(B_storage, TBFs_storage)
        print(f"âœ” B_storage è®¡ç®—å®Œæˆ: {B_storage.shape}")

        # -------- 3ï¸âƒ£ L çŸ©é˜µä» l_file è·å– --------
        L_dict = sio.loadmat(temp_file_paths['l'])
        L_data = next((v for k, v in L_dict.items() if isinstance(v, np.ndarray) and not k.startswith('__')), None)
        if L_data is None:
            return jsonify({"error": "l_file æ— æ³•è¯†åˆ«ä¸»è¦çš„ L çŸ©é˜µå˜é‡"}), 400

        print(f"âœ” L åŠ è½½æˆåŠŸ: {L_data.shape}")

        # -------- 4ï¸âƒ£ Cortex ä¿¡æ¯è¯»å– --------
        Cortex_dict = sio.loadmat(temp_file_paths['cortex'])
        Cortex_data = Cortex_dict.get('Cortex')
        # å°è¯•è§£åŒ… MATLAB ç»“æ„ä½“
        if Cortex_data is not None and Cortex_data.ndim >= 2 and Cortex_data.shape[0] > 0 and Cortex_data.shape[1] > 0:
            Cortex_dict_unpacked = Cortex_data[0][0]
        else:
            Cortex_dict_unpacked = Cortex_data  # å°è¯•ç›´æ¥ä½¿ç”¨é¡¶å±‚å˜é‡

        if Cortex_dict_unpacked is None:
            return jsonify({"error": "cortex_file æ— æ³•æå– Cortex ç»“æ„ä½“"}), 400


        if selected_gain is None or B_storage is None or Cortex_dict is None or L_data is None:
            return jsonify({"error": "æ— æ³•ä»ä¸Šä¼ æ–‡ä»¶ä¸­è§£æå‡º Gain æˆ– B_storageæˆ– L çŸ©é˜µæˆ–Cortexã€‚è¯·æ£€æŸ¥å˜é‡åæ˜¯å¦æ­£ç¡®ã€‚"}), 400

        Gain = selected_gain

        # ç¡®ä¿ B_storage æ˜¯ä¸‰ç»´ (N_ç‰‡æ®µ x nSensor x nSnap)
        if B_storage.ndim == 2:
            B_storage = B_storage[np.newaxis, :, :]

        n_segments = B_storage.shape[0]
        n_sensor = B_storage.shape[1]

        # 3. åˆå§‹åŒ–ç»“æœå­˜å‚¨å­—å…¸
        results_data = {}
        ratio = 1

        all_s_reco = []
        all_kernels = []

        # 4. ç®—æ³•é€‰æ‹©å’Œæ‰§è¡Œ

        if algorithm == 'sbl':
            print(f"--- æ­£åœ¨è¿è¡Œ SBL (Sparse Bayesian Learning)ï¼Œå…± {n_segments} ä¸ªç‰‡æ®µ ---")

            for i in range(n_segments):
                B_i = B_storage[i, :, :].astype(np.float64)

                # è°ƒç”¨ SBL_solver
                Kernel_sbl, par_sbl = SBL_solver(
                    B=B_i,
                    L=L_data,
                    epsilon=1e-4,  # åœæ­¢æ¡ä»¶
                    flags=1,
                    prune=[1, 1e-6],
                    Cov_n=np.eye(n_sensor),
                    print_progress=1
                )
                print(f"B_içš„å½¢çŠ¶ï¼š{B_i.shape}")
                print(f"æ ¸çš„å½¢çŠ¶ï¼š{Kernel_sbl.shape}")
                all_kernels.append(Kernel_sbl)
                S_SBL = Kernel_sbl @ B_i * ratio
                all_s_reco.append(S_SBL)


            results_data[f'S_{algorithm.upper()}'] = all_s_reco

        elif algorithm in ['wmne', 'sloreta']:
            print(f"--- æ­£åœ¨è¿è¡Œ MNE/LORETA ç®—æ³• ({algorithm})ï¼Œå…± {n_segments} ä¸ªç‰‡æ®µ ---")


            for i in range(n_segments):
                B_i = B_storage[i, :, :]

                # è°ƒç”¨ MNE_solver
                Kernel_i, params_i = MNE_solver(
                    B=B_i,
                    Gain=Gain,
                    L=L_data,  # å‡è®¾ L_whitened = Gain
                    Cortex=Cortex_dict,
                    InverseMethod=algorithm,
                    Reg=1
                )
                all_kernels.append(Kernel_i)
                S_SBL = Kernel_i @ B_i * ratio
                all_s_reco.append(S_SBL)

            results_data[f'S_{algorithm.upper()}'] = all_s_reco

        elif algorithm == 'duvl1n':
            print(f"--- æ­£åœ¨è¿è¡Œ DUVL1N ç®—æ³• ({algorithm})ï¼Œå…± {n_segments} ä¸ªç‰‡æ®µ ---")
            # === æ¨¡å‹è·¯å¾„å¤„ç† ===
            model_dir = os.path.join(os.path.dirname(__file__), "source_mind\log_duvl1n")
            model_filename = "0.0037918177-DUV-lam0.00001rho600000-L1N-2d-2d-600-0.001-_model_20251124_191904_78.pth"
            model_path = os.path.join(model_dir, model_filename)

            if not os.path.exists(model_path):
                return jsonify({"error": f"DUVL1N æ¨¡å‹æ–‡ä»¶æœªæ‰¾åˆ°: {model_path}"}), 500
            L_tensor = torch.from_numpy(L_data.astype(np.float32))
            # === åŠ è½½æ¨¡å‹ ===
            try:
                model = ESINetADMMLayer(L_tensor)
                params_load = torch.load(model_path, map_location='cpu')  # å…¼å®¹æ—  GPU ç¯å¢ƒ
                model.load_state_dict(params_load)
                model.eval()
            except Exception as e:
                return jsonify({"error": f"åŠ è½½ DUVL1N æ¨¡å‹å¤±è´¥: {str(e)}"}), 500

            # === éªŒè¯ TBFs ç»´åº¦ ===
            if TBFs_storage.ndim != 2:
                return jsonify({"error": "TBFs å¿…é¡»æ˜¯äºŒç»´çŸ©é˜µ (K x nSnap)"}), 400
            n_snap = B_storage.shape[2]
            if TBFs_storage.shape[1] != n_snap:
                return jsonify({
                    "error": f"TBFs æ—¶é—´ç»´åº¦ ({TBFs_storage.shape[1]}) ä¸ B æ•°æ® ({n_snap}) ä¸åŒ¹é…"
                }), 400

            with torch.no_grad():
                for i in range(n_segments):
                    B_i = B_storage[i, :, :]  # shape: (n_sensor, n_snap)

                    # è½¬æ¢ä¸º PyTorch å¼ é‡
                    B_i_tensor = torch.from_numpy(B_i.astype(np.float32))  # (62, 300)
                    TBFs_tensor = torch.from_numpy(TBFs_storage.astype(np.float32))  # (K, 300)

                    # è®¡ç®— B_trans = B_i @ TBFs^T â†’ (62, K)
                    B_trans = torch.matmul(B_i_tensor, TBFs_tensor.t())  # æ³¨æ„ï¼š.t() æ˜¯ PyTorch çš„è½¬ç½®

                    # æ„å»ºè¾“å…¥å­—å…¸
                    x = {'B_trans': B_trans.unsqueeze(0)}  # æ·»åŠ  batch ç»´åº¦ â†’ (1, 62, K)

                    # å‰å‘ä¼ æ’­
                    s_gen_trans = model(x)  # è¾“å‡º shape: (1, n_dipole, K)

                    # å»é™¤ batch ç»´åº¦
                    s_gen_temp = s_gen_trans.squeeze(0)  # (n_dipole, K)

                    # é‡æ„æ—¶é—´åºåˆ—: S = s_gen_temp @ TBFs â†’ (n_dipole, n_snap)
                    s_gen = torch.matmul(s_gen_temp, TBFs_tensor)  # (n_dipole, 300)

                    # è½¬ä¸º NumPy å¹¶ä¿å­˜
                    S_L1N = s_gen.cpu().numpy().astype(np.float64)
                    all_s_reco.append(S_L1N)

            results_data[f'S_{algorithm.upper()}'] = all_s_reco

        else:
            return jsonify({"error": f"ä¸æ”¯æŒçš„ç®—æ³•: {algorithm}"}), 400

        print(f"âœ… ç®—æ³• {algorithm} è®¡ç®—å®Œæˆã€‚")


        # filename = f"{algorithm}_source_results.mat"
        # save_path = os.path.join(RESULT_DIR, filename)
        #
        # # ä¿å­˜ MATLAB æ•°æ®æ–‡ä»¶
        # sio.savemat(save_path, results_data)
        # 6. â­ å…³é”®æ­¥éª¤ï¼šå°†ç»“æœå†™å…¥å†…å­˜ç¼“å†²åŒºå¹¶å‘é€ç»™å®¢æˆ·ç«¯
        output = io.BytesIO()
        sio.savemat(output, results_data)
        output.seek(0)  # å°†æŒ‡é’ˆé‡ç½®åˆ°æ–‡ä»¶å¼€å¤´

        filename = f"{algorithm}_source_results.mat"

        # ä½¿ç”¨ send_file ä»å†…å­˜ç¼“å†²åŒºç›´æ¥ä¸‹è½½æ–‡ä»¶
        response = send_file(
            output,
            as_attachment=True,
            download_name=filename,
            mimetype="application/x-matlab"
        )

        return response
    except Exception as e:
        # æ‰“å°è¯¦ç»†é”™è¯¯åˆ°æœåŠ¡å™¨æ§åˆ¶å°
        import traceback
        traceback.print_exc()
        print(f"ğŸš¨ è‡´å‘½é”™è¯¯: {e}")
        # è¿”å› 500 é”™è¯¯ç å’Œè¯¦ç»†é”™è¯¯ä¿¡æ¯ç»™å‰ç«¯
        return jsonify({"error": f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯ï¼Œè¯·æ£€æŸ¥æ§åˆ¶å°è¾“å‡ºã€‚è¯¦ç»†ä¿¡æ¯: {str(e)}"}), 500

    finally:
        # -------------------------------------------------------------
        # âœ… æ¸…ç†æœºåˆ¶ï¼šä½¿ç”¨ finally å—ç¡®ä¿ä¸Šä¼ çš„ä¸´æ—¶è¾“å…¥æ–‡ä»¶è¢«åˆ é™¤
        # -------------------------------------------------------------
        for key, path in temp_file_paths.items():
            if os.path.exists(path):
                try:
                    os.remove(path)
                    print(f"âœ” è¯·æ±‚ç»“æŸï¼Œå·²æ¸…ç†ä¸´æ—¶è¾“å…¥æ–‡ä»¶: {path}")
                except OSError as e:
                    print(f"âš ï¸ æ— æ³•åˆ é™¤ä¸´æ—¶è¾“å…¥æ–‡ä»¶ {path}: {e}")


# -------------------------------------------------------------
# å¯åŠ¨æœåŠ¡å™¨
if __name__ == '__main__':
    print("=" * 40)
    print("--- å¯åŠ¨ Flask æœåŠ¡å™¨ ---")
    print("è¯·è®¿é—® http://127.0.0.1:5000/ è¿è¡Œå‰ç«¯ã€‚")
    print("=" * 40)
    app.run(host='0.0.0.0', port=5000, debug=True)